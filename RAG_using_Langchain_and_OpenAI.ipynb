{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxvH0Fhi41uXb2evpnBn/d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sachinmkotian/CloudxLabs_sachin_2024/blob/main/RAG_using_Langchain_and_OpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4kpRMPWrx5F"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain\n",
        "\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['OPENAI_API_KEY'] = \"******\"\n",
        "os.environ['LANGCHAIN_API_KEY'] = \"******\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"default\""
      ],
      "metadata": {
        "id": "ys4_GID631M4"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n"
      ],
      "metadata": {
        "id": "5z5anNudwoKn"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Indexing existing documents\n",
        "#Indexing : Fish out documents similar to my question...\n",
        "#Document with similar words are in similar space...this is the fundamental idea for Indexing\n",
        "#Questions are then compared to the documents based on numerical comparisions\n",
        "\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "    bs_kwargs=dict(\n",
        "        #Use BeautifulSoup library to parse objects\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\",\"post-title\",\"post-header\")\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "#creates dict type objects\n",
        "blog_docs = loader.load()\n",
        "\n",
        "#Split\n",
        "# Use RecursiveCharacterTextSplitter Recursively tries to split by different characters to find one that works\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=300,chunk_overlap=50)\n",
        "splits = text_splitter.split_documents(blog_docs)\n",
        "\n",
        "#Retrieval\n",
        "#Convert documents to numerical representations which can be searched aka Embedding\n",
        "#Documents are split and compressed to a Vector. Vectors are indexed\n",
        "#Store the documents in a Chroma vector using OpenAI Embeddings\n",
        "vectorstore = Chroma.from_documents(documents=splits,embedding=OpenAIEmbeddings())\n",
        "\n",
        "#vector store retriever is a retriever that uses a vector store to retrieve documents. It is a lightweight wrapper around the vector store class to make it conform to the retriever interface.\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
        "docs = retriever.get_relevant_documents(\"What is task decomposition?\")\n",
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8V61XQV7B4k",
        "outputId": "9319360e-4d46-49c5-b92b-e1e2cfabe388"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Generation\n",
        "\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "#A prompt template is a prompt that includes replaceable variables.\n",
        "#Prompt templates enable you to test how different prompt formats perform with different prompt data, without requiring you to write multiple individual prompts.\n",
        "\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question:{question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "prompt\n",
        "\n",
        "#LLM\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0)\n",
        "\n",
        "#langchain has a expression language\n",
        "chain = prompt | llm\n",
        "\n",
        "chain.invoke({\"context\":docs,\"question\":\"What is task decomposition?\"})\n",
        "\n",
        "from langchain import hub\n",
        "\n",
        "#Pull Langchain prompt object which has human text.\n",
        "prompt_hub_rag = hub.pull(\"rlm/rag-prompt\")\n",
        "prompt_hub_rag\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwwG2NVa78rn",
        "outputId": "5bb99927-e54a-4a8a-809a-f94cd10d2019"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n",
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = (\n",
        "    {\"context\":retriever, \"question\":RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "#StrOuputParser is a OutputParser that parses LLMResult into the top likely string\n",
        "rag_chain.invoke(\"Can you give a Agent System Overview in 5 points?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "yCy8MCQLABXQ",
        "outputId": "8d920af5-7495-4e73-bf4b-4d8157a71935"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n",
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1. Utilizes internet access for searches and information gathering.\\n2. Manages long term memory effectively.\\n3. Employs GPT-3.5 powered Agents for delegation of simple tasks.\\n4. Outputs files as needed.\\n5. Evaluates performance by continuously reviewing actions, self-criticizing behavior, reflecting on past decisions, and aiming for efficiency in task completion.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5wQPtG7PAmZa"
      },
      "execution_count": 76,
      "outputs": []
    }
  ]
}